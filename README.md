# Robot-Monkeys-Crowd-Computing
A repository containing group work for the Crowd Computing Course at TU Delft

> Useful links:
> - [Overleaf Document](https://www.overleaf.com/project/5eb3356fc184ea0001895621)
> - [Google Drive folder](https://drive.google.com/drive/folders/1PWEe0p09HA65QKg9iBCxWdSSIrie55Ae?usp=sharing)
> - [Midterm Presentation Slides](https://docs.google.com/presentation/d/11CL6IM0RIl1mIglDF-Zxc5HlIBibgB_-hA9_wYWYxoE/edit?usp=sharing)

## Up for Improvement

- __Novelty__
  - It's not clear why the system is unique (_The innovation appears to stem from the exploration of what the best HIT design for this task is_)
- __Personas__
  - Identify real personas involved (_no personas really developed_)
  - User classes well linked to requirements, but are incorrectly called personas

- __Task Design__
  - Missing arguments and rationale to support the task designs
  - State if the selected task designs are based on our intuition or on previous work
  - Identify the expected/hypothesised effect of the different designs
  - Workflow not explicit -- what is the relationship between the matching exercise HIT and the Odd-one-out HIT?
  - How will you consider knowledge and experience in the task assignment?
- __Incentives__
  - Not well justified
- __Quality Control__
  - Explain the choice of values 3, 5, 7
  - Explain what is the level of expertise: is it with the UI? With AMT?  With the domain of the entities?
  - How are the test related to the items in the task? What makes these tests useful? 
- __Evaluation__
  - Not well justified
  - Is not only in terms of the quality of the final result (needs improvement)
