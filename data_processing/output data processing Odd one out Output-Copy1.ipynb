{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_wise_out = pd.read_csv(\"Output/leave-one-out.csv\") \n",
    "pair_wise_in = pd.read_csv(\"Odd-one-out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=[]\n",
    "for i,j in zip(pair_wise_out[\"Input.Record1\"].value_counts().index,pair_wise_out[\"Input.Record1\"].value_counts().values):\n",
    "    df = [pair_wise_out[pair_wise_out[\"Input.Record1\"]==i][\"Input.Label\"].values[0]]*j\n",
    "    true.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 4, 4, 4, 4, 4, 4],\n",
       " [1, 1, 1, 1, 1, 1, 1],\n",
       " [2, 2, 2, 2, 2, 2, 2],\n",
       " [3, 3, 3, 3, 3, 3, 3],\n",
       " [3, 3, 3, 3, 3, 3, 3],\n",
       " [2, 2, 2, 2, 2, 2, 2],\n",
       " [2, 2, 2, 2, 2, 2, 2],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [4, 4, 4, 4, 4, 4, 4],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1],\n",
       " [2, 2, 2, 2, 2, 2, 2],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [2, 2, 2, 2, 2, 2, 2],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [3, 3, 3, 3, 3, 3, 3],\n",
       " [4, 4, 4, 4, 4, 4, 4],\n",
       " [4, 4, 4, 4, 4, 4, 4],\n",
       " [3, 3, 3, 3, 3, 3, 3],\n",
       " [1, 1, 1, 1, 1, 1, 1],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [4, 4, 4, 4, 4, 4, 4],\n",
       " [1, 1, 1, 1, 1, 1, 1],\n",
       " [4, 4, 4, 4, 4, 4, 4],\n",
       " [2, 2, 2, 2, 2, 2, 2],\n",
       " [3, 3, 3, 3, 3, 3, 3],\n",
       " [0, 0, 0, 0, 0, 0, 0],\n",
       " [4, 4, 4, 4, 4, 4, 4]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=[]\n",
    "for i in pair_wise_out[\"Input.Record1\"].value_counts().index:\n",
    "    df = pair_wise_out[pair_wise_out[\"Input.Record1\"]==i][\"Answer.one-out.label\"].values.ravel()\n",
    "    outputs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_outputs=[]\n",
    "for i in list(outputs):\n",
    "    for j in i:\n",
    "        worker_outputs.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_outputs=[]\n",
    "for i in list(true):\n",
    "    for j in i:\n",
    "        true_outputs.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_labels=worker_outputs\n",
    "numeric_ol = []\n",
    "for i in output_labels:\n",
    "    if i==\"Item 1\":\n",
    "        numeric_ol.append(1)\n",
    "    elif i==\"Item 2\":\n",
    "        numeric_ol.append(2)\n",
    "    elif i==\"Item 3\":\n",
    "        numeric_ol.append(3)\n",
    "    elif i==\"Item 4\":\n",
    "        numeric_ol.append(4) \n",
    "    else:\n",
    "        numeric_ol.append(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numeric_ol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multilabel_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-165c017979f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_ol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'multilabel_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "multilabel_confusion_matrix(true_outputs, numeric_ol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "tn, fp, fn, tp=multilabel_confusion_matrix(true_outputs, numeric_ol).ravel().reshape(-1,4).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162.0, 6.0, 6.0, 36.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = tp/(tp+fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec= tp/(tp+fp)\n",
    "prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2*prec*recall/(prec+recall) \n",
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority voting with 7.\n",
    "single_label_7=[]\n",
    "for i in (worker_labels):\n",
    "    (single_label_7.append(pd.Series(i).value_counts().index[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_label_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision, recall, f_score.\n",
    "precision_recall_fscore_support(true_labels, single_label_7, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision_recall curve is not possible as no probabilities are involved in the sense that majority voting is used to determine labels and not a classifier for which the threshold can be varied!^<<..>>./\\../\\. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[22,  0],\n",
       "        [ 0,  8]],\n",
       "\n",
       "       [[26,  0],\n",
       "        [ 0,  4]],\n",
       "\n",
       "       [[24,  0],\n",
       "        [ 0,  6]],\n",
       "\n",
       "       [[25,  0],\n",
       "        [ 0,  5]],\n",
       "\n",
       "       [[23,  0],\n",
       "        [ 0,  7]]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(true_labels, single_label_7)# its the same for 5 workers here. \n",
    "#Nothing really to see here all True positives and True negatives are correctly identified for all different options basically..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
